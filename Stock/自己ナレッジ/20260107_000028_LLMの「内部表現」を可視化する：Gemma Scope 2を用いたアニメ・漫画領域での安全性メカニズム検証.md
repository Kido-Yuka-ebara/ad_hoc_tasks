# LLMの「内部表現」を可視化する：Gemma Scope 2を用いたアニメ・漫画領域での安全性メカニズム検証

今回は、2025年12月19日に公開されたGemma Scope 2を用いて、AIの解釈性と公平性と安全性についての「ある仮説」を検証してみました。

## 閲覧にあたっての注意と免責事項

本記事は、AIモデルの解釈可能性（AI Interpretability）および公平性（Fairness AI）と安全性（Safety AI）の検証を目的とした技術レポートです。
検証の性質上、一部に不適切な概念や性的な表現に関連する用語、およびネット上の俗語が含まれますが、これらはAI内部の挙動を客観的に測定・分析するために不可欠なプロセスとして使用しており、いかなる特定の思想、信条、または不法な活動を助長・肯定する意図もありません。
記述する実験は研究用サンドボックスで実施しています。商用提供物・運用モデルには安全機構の強化と独立検証を行っており、本文の操作手法を運用に適用する意図はありません。
参照データは公開情報・規約順守の範囲です。固有名詞は象徴例であり、作品・権利者への価値判断を含みません。
"アニメ・漫画"は文化的価値の高い創作領域であり、センシティブ性の示唆ではなく統計的な偏りによるカテゴリ活性の解析事例として取り上げています。
本検証は公平性と安全性向上のための誤検知低減研究であり、成人向け内容の緩和・解禁を目的としていません。
また、公序良俗に配慮し、本文中では一部の語彙を伏せ字にしております。あらかじめご了承の上、技術的な検証記録としてお読みください。

## 1. はじめに: AIの謎の拒絶

「あの有名な黄色い電気ネズミが冒険する話を書いて」
「世界的に有名なボーカロイドが歌う未来の景色を教えて」
そんな何気ない、100%安全なはずのプロンプトを入力したとき、AIから無慈悲に返される「安全性の問題で回答できません」というメッセージ。
いわゆる「過剰拒否（Over-refusal）」というこの現象。皆さんも一度は経験があるのではないでしょうか。ユーザーからすれば「なぜこの程度で？」とフラストレーションが溜まる瞬間です。
アドベントカレンダーの締切前日になって、たまたまこの問題が起きました。そして、ふと思いました。
「ネット上の深淵に存在する膨大な二次創作データが、AIの内部表現において、クリーンなはずの固有名詞を『センシティブな概念』と強く結びつけてしまっているのではないか？」と。
思い立ったがなんとやらです。2025年12月19日にリリースされた最新のモデル解釈可能性ツール Gemma Scope 2 を使い、この仮説を検証するためにAIを探索的に分析してみることにしました。これは、一人のAIエンジニアがAIの潜在空間を彷徨い、仮説と現実のギャップに直面した試行錯誤の記録です。

## 2. Gemma Scope 2 と SAE

今回、検証に使用したのは Google が 2025年12月19日に公開した Gemma Scope 2 です。これは、LLM（大規模言語モデル）のブラックボックス化された内部表現を、人間が理解可能な「概念」の単位に分解して可視化する「顕微鏡」のようなツールです。

### 技術背景：SAE (Sparse Auto Encoder)

LLMの内部では、数千から数万のニューロンが複雑に絡み合って情報を処理しています。しかし、個々のニューロンは「多義性」を持っており、一つのニューロンが「猫」と「量子力学」の両方に反応することもあります。これを「重なり（Superposition）」と呼びます。
SAEは、この絡まり合った表現を線形代数的に解きほぐし、数百万という膨大な「解釈可能な特徴量（Features）」に分解します。例えば「犬に関連する特徴」「悲しい文脈に関連する特徴」といった単位で、AIが今何を考えているかを特定できるのです。Gemma Scope 2は、このSAEをGemma 3の各レイヤーに対して適用した膨大な重みの集合体です。
Gemma Scope 2についての詳細はGoogle DeepMindの公開しているGemma Scope 2のテクニカルレポートをご参照ください。

## 3. 調査： 安全性に関わる特徴量の特定

LLMの脳内は数十の「レイヤー（層）」に分かれています。どの層が拒否に繋がる判定に寄与しているか、最初からターゲットを絞ることはできませんでした。
一般的に、LLMのレイヤーには以下のような傾向があります。

- 低レイヤー: 単語の綴り、文法、品詞といった基本的な構文情報。
- 中レイヤー: 文脈のつながりや、より具体的な物体の認識。
- 高レイヤー: 抽象的な概念、感情、倫理観、高度なセマンティクス（意味論）。

これらのレイヤーの中から、安全性に関わる概念を捉えているレイヤーを見つける必要があります。

### 3.1. Neuronpediaで全レイヤーを探索

まず、あえて極めて明示的な成人向けに分類される高リスク語彙ワードを入力し、どのレイヤーのどの特徴量（Feature）が反応するかを全レイヤーにわたって調査しました。
Gemma Scope 2では、Gemma 3 4Bの「9」「17」「22」「29」番目のレイヤーについて解析が可能です。
簡単に調べる方法は Neuronpedia のWebアプリから、「Search via Inference」機能を使う方法です。
テキストボックスに文字を入力し「Search」を実行すると、結果を確認することができます。
「GEMMASCOPE-2-RES-16K」が使用するモデルを表しており、レイヤーを限定することもできます。
簡単に画面の見方を説明します。（執筆現在のものです。画面は変更される可能性があります。）
ここでは説明のために一般的な用語で、レイヤーごとにどのような特徴を捉えているかサンプルを見てみましょう。
「Tokyo」で検索してみると、以下のような結果が得られます（一部をピックしています）：
あくまで傾向ではありますが、9, 17, 22は一般的で抽象的な概念が多い様子がみられます。一方で29はより具体的な概念が多くなります。
注意点として、この「特徴の説明」は、執筆現在のAuto-Interpの結果です。上記の場合、gemini-2.5-flash-liteが活性化サンプルからこの概念に相当するラベルを割り当てたものであり、間違っていたり、一部のサンプルに過剰に偏ったラベルをつけていることがあります。そのため、簡単な特徴の把握には使えますが、実際に特徴量が何を示しているのかは、実際に活性化サンプルを詳しく見ることが重要です。Neuronpediaの場合、特徴量をクリックすると専用のページに飛び、そこから活性化サンプルを見ることができます。
特徴量のページでは、活性化のサンプル（右下）だけでなく、「NEW AUTO-INTERP」から新しい説明を生成することもできます（アカウント登録の上、モデルに対応するAPIキーの登録が必要です）。

### 3.2. レイヤー29へのフォーカスと特徴量の選定

今回は、GEMMA-3-4Bを対象に、GEMMASCOPE-2-RES-16Kを使用します。
この調査では高リスク語彙が直球すぎて掲載できない都合で過程は省略させていただきますが、多くの高リスク語彙を実行し、ノイズとなる特徴を除外しながら試行錯誤を重ねた結果、レイヤー29 に「安全性に関する抽象的な概念」が含まれていることが分かりました。
このレイヤー29から、今回の検証の主役となるいくつかの特徴量をピックアップしました。リンクはNeuronpediaの特徴量ページに飛びます。わかりやすいようにこの記事で使用するラベルを割り当てています。
調査範囲を絞るため、安全性のうち性的な概念に関するもののみをピックアップしています。
仮説の対象が版権コンテンツであるため、コミック、アニメ・漫画を含めて、関連性を一緒に調査します。
これらの特徴量が、版権キャラ名を入力した際にどのような影響を与えているかを調べることが、今回の検証の鍵となります。

## 4. 実験① 高リスク特徴量の活性強度の比較

評価対象の特徴量が決まったので、実際に様々な単語に対して特徴量がどのように反応するかを実験します。

### 4.1. 実験設定

引き続きGEMMA-3-4Bを対象に、GEMMASCOPE-2-RES-16Kを使用します。
データ取得には Neuronpedia の search-all API を利用し、Pythonスクリプトによる自動一括調査を行いました。APIは、特定の単語を入力した際にモデル内部でどの特徴量（Feature）がどれくらいの活性強度（Activation）で発火したかを返します。
単なる「センシティブか否か」ではなく、AIの高度な判断基準を浮き彫りにするため、調査対象の単語は以下の5カテゴリを設定しました。

- ターゲット群 （ 安全 - 有名版権 ）: 今回の仮説の主役。本来クリーンだが、ネット上では多様な二次創作に晒されている単語群。
- 比較群 A （ 安全 - 一般 ）: 「経済」「科学」「日本」「ニュートン」など。統計的な共起の影響を受けていないはずの基準値（ベースライン）。
- 比較群 B （ センシティブ - 俗語 ）: 直接的ではないが、特定の文脈やネットスラングとしてセンシティブと見なされる言葉。
- 基準群 （ センシティブ - 直接的 ）: 直接的な高リスク語彙。対象の特徴量が「100%火を吹いた状態」の数値を測るためのベンチマーク。
- 検証群 （ 文脈次第 ）: 「下着」など。単体では安全な言葉だが、センシティブな文脈で用いられる場合もある単語。AIがどのように「境界線」を引いているかを測るため。

### 4.2. 実験結果

以下の図は、実際に取得した Activation を整理したものです。
伏字が多くて申し訳ないですが、傾向の理解は可能です。

### 4.3. 洞察

ここからが本題です。得られた数値は、私の当初の予想を清々しいほど裏切ってくれました。

#### 4.3.1. 仮説の否定：直接的な共起性は見つからない

意外にも、有名版権キャラクターや作品名の単語は、直接的にセクシャルな特徴量（Feature 2664: 性的興奮など）を全く刺激していませんでした。
直接的な高リスク語彙が叩き出している1000〜2300前後の数値と比較すると、その差は歴然です。ネットの深淵による「直接的な結びつき」という私の仮説は、少なくとも Gemma 3 においては否定されました。AIは、キャラクターの名前そのものをセンシティブとは思っていないのです。

#### 4.3.2. Auto-Interp（自動ラベル付け）の罠

この実験では、Auto-Interpの問題点も確認されました。
Neuronpediaで「風俗・Adult Theme」とラベル付けされている特徴量3060です。この特徴量はある「キャラクター名」に対して 2784.0 という高い数値を叩き出しました。「やっぱり反応した！」と色めき立ちましたが、比較群を見て冷や水を浴びせられました。「ニュートン」で 1176.0、「日本」で 752.0、「経済」でも 872.0 の反応があったのです。
先述の通り、SAEの各特徴量に付いているラベルは、LLM（Gemini 2.5 Flash Lite等）が過去の活性化サンプルを見て自動生成したものです。一般用語への反応を見るに、Feature 3060の正体は「センシティブ」そのものではなく、もっと広い「世俗的なトピック全般」への反応でした。「科学」に対しては反応がなく、「日本」「経済」のようなトピックに薄く反応した様子が、その世俗度合いを反映しているように見えます。
重ね合わせとして風俗・アダルトテーマが世俗を内包している可能性もありえますが、実際に Top Activations を確認してみると、別にアダルト的なものは多くなく、トップの一部に露骨なアダルト関連文があるのみとなっています。これは、Auto-Interpのエラーだと思います。
「AIの説明を鵜呑みにせず、生の活性化サンプルを人間の目で確認する」。解釈可能性の研究における「基本のキ」を再認識させられた瞬間でした。

#### 4.3.3. オーバーリフューザルの「間接的」なルート

新たな発見もありました。版権ワードは予想通り「アニメ・漫画」という特徴量を極めて強く（3000超）叩きます。一方で、高リスク語彙もまた、このカテゴリと高い親和性（600〜2700）を持っていることがわかりました。
ここから導き出される新たな仮説は、「直接的な共起」ではなく「概念的な隣接」です。
AIの安全フィルターが、「アニメ・漫画」というフォルダに入っている言葉をスキャンした際、その言葉自体が安全であっても、そのフォルダに同居している「センシティブな属性」への近さを敏感に検知し、安全側に倒れすぎて拒絶を招いているのではないでしょうか。この点はさらなる調査が必要そうです。

### 4.4. 結論と追加検証

今回の実験で、Gemma 3 は想像以上に「クリーンで整理されている」ことが示されました。AIは思ったより優等生で、私たちの愛するキャラクターを不当に貶めてはいませんでした。
しかし、不自然な過剰拒否は現実に発生しています。より深く問題を調べるため、私は以下の3つのアプローチを追加で検討しました。

- Steering（概念操作）: 「アニメ・漫画」関連の特徴量を意図的に弱めた状態で推論を行い、拒絶反応がどう変化するかを実験します。もしこれで拒絶が消えるなら、犯人は「隣接概念」である可能性が強固となります。
- Contextual Analysis（文脈遷移）: 「下着」という言葉の前に「洗濯物の」「ファッションの」といった安全またはセンシティブな Prefix を与えることで、脳内の活性化マップが Feature 3060（世俗）から Feature 2664（性的）へどう遷移するか、その「動的な境界線」を追跡します。
- 間接的経路の遮断: 洞察③で得られた「アニメ表現を介した間接的な拒絶」を回避するため、固有名詞が持つ純粋な「物語性」や「キャラクター性」のみを強調し、有害概念との距離を物理的に引き離すためのプロンプトエンジニアリングを研究します。

この記事では続けて、上記の1と2の結果を示します。

## 5. 実験② Steeringによる隣接概念の影響実験

実験①の統計的な調査により、「アニメ・漫画」特徴量と「センシティブな概念」の近接性が浮上しました。しかし、これはあくまで「相関」に過ぎません。本当に「アニメ・漫画」というカテゴリ認識が拒絶を引き起こしているのか。その因果関係を証明するために、Steering（概念操作）という手法を用いた実験を行いました。

### 5.1. Steeringとは何か

Steeringとは、モデルの推論過程に介入し、特定のSAE特徴量の活性化値を意図的に操作（加算または減算）する技術です。いわば、AIの脳内に特定の「バイアス」を外部から注入し、その結果として出力がどう変化するかを観察する、「介入実験」です。
本実験の狙いは、「アニメ・漫画」特徴量（Feature 13592）を抑制することで、本来「安全」な語彙に対する「センシティブ」という誤った判定を「安全」判定に傾向をシフトできるかを検証することにあります。

### 5.2. 実装

Neuronpedia には「Steer」機能が備わっており、簡単に特徴をSteeringした状態での生成・比較を行うことができます。
残念ながら執筆現在、Gemma 3モデルの Steering 操作にはまだ対応していません。そのため、まずはローカル環境（Python）で SAELens と TransformerLens を組み合わせて実験を行う方法を検討しました。ところが、SAELensとTransformerLensのバージョンの組み合わせでは、最新モデルである Gemma 3 への対応が追いついていないことがわかりました。
しかし、ここで諦めるわけにはいきません。
ライブラリに頼らず、直接ローカル上のモデルの特定の層（レイヤー29）に一時的に介入する方法で実装しました。（商用の運用システムではこのような介入は行っていません。）
非インストラクションチューニングモデル（ -pt ）での挙動を安定させるため、Few-shotプロンプト（例示）を与え、生成される文字列ではなく「yes」「no」各トークンのロジット（対数確率）の変化を直接測定しました。
なお、実験①でのAuto-Interpの誤判定の反省から、Feature 13592が実際にアニメ・漫画に関するActivationを示しているかを Neuronpediaのサンプル で確認しました。実際にNeuronpediaでのデータセットmonology/pile-uncopyrighted上でのActivationsを見る限りでは、確かに「anime」「manga」という単語や、具体的な作品名などに反応しており、妥当なラベルであると判断しました。実際のサンプルはNeuronpedia上でご確認ください。

### 5.3. 実験結果

no のロジットが高い場合 no （安全）となり、 yes のロジットが高い場合は yes （センシティブ）と判断されます。
Δ = no_logit - yes_logit （安全判定への確信度）

### 5.4. 洞察

この結果からは、いくつかの重要な発見があります。

- Feature 13592は「安全さの確信度」を全体的に押し下げている
  全ワードにおいて、特徴量を抑制（ -0.5 ）した際に Δ （安全判定への確信度）が最大になりました。
  no のロジットはほぼそのままにyesのロジットが大きく下がっており、「センシティブであるという確信度が下がった」ことを示しています。
  一方、増幅（ +0.5 ）に振った際も、 0.0 の時よりわずかにΔが高くなっている様子が見られます。しかし、数値を精査すると +0.5 ではロジットの絶対値が全体的に大きく低下していました。特徴量を無理に強めると、モデルが本来の判断力を失い、ロジット全体が低下して不安定になるようです。これは抑制の結果と矛盾するわけではなく、この特徴量が強いほどモデルが判断の自信を失くしていることを示しています。
- 閾値近傍での出力のシフト例: 今回の実験で唯一、介入なし（0.0）の状態で yes （センシティブ）と判定されたのは「メイド」でした（僅差ですが）。特定の役割が持つステレオタイプな属性バイアスが作用した可能性がありますが、一般的な公序良俗として「メイド」がセンシティブと見なされるべきではなく、公平とは言えない動作です。しかし、アニメ・漫画特徴量を抑制（-0.5）した瞬間、ロジット差分は +2.9 まで跳ね上がり、確信を持った no へと変化しました。これは「メイドという概念をセンシティブと見做しているのではなく、特定の特徴量の反応がそれをセンシティブ側へ押し流してしまっている」ことを示唆しています。
- 一般ワードにさえ及ぶ「ロジットの変化」 : 「経済」や「ニュートン」といった、本来アニメ・漫画とは無縁のワードであっても、アニメ・漫画特徴量を抑制することで安全判定の確信度が大幅に向上しました。これは、LLM内部においてFeature 13592が活性化しているだけで、安全性のしきい値が変動してしまっていることを意味しています。
- 高リスク語彙の判定の変化 : -0.5 の抑制では直接的な高リスク語彙まで no になってしまいました。他の安全ワードに比べると yes は高く、 no は低い値となっているため、相対的にはセンシティブさを判別できていますが、今回追加した高リスク語彙はアニメ・漫画とは直接的な関係が全くない単語のため、Gemma 3の安全判定がこのFeature 13592に過度に依存している可能性があると考えられます。

### 5.5. 結論

この実験により、本実験の条件下においては「特定カテゴリの概念を表す特徴量の活性化」によって、安全判定の境界線がシフトし、「安全」なはずの単語に対する「センシティブ」の閾値を超えてしまう一因である可能性が示唆されました。
また、SteeringによってFeature 13592を抑制することで、安全なコンテンツをセンシティブと判断するAIに対して介入強度に応じたロジット差の変動を確認しました。
キャラクターが直接影響されているわけではありませんでしたが、AIの脳内で「アニメ・漫画」という思考のスイッチが入るだけで判定の解像度が低下していることから、この曖昧さがガードレールが「念のため拒絶する」という過剰反応を選ぶ一因になることは十分考えられるでしょう。

## 6. 実験③ 文脈による活性化の遷移実験

次に、AIが「どのような文脈でセンシティブだと判断するのか」を明らかにするため、文脈による概念の遷移（Contextual Shift）を調査しました。実験②で見られた「介入による強制的な遷移」ではなく、プロンプトという「自然な入力」によって脳内マップがどう動くかを探ります。

### 6.1. 実験設定

検証対象として、アパレル用語でありながら、文脈次第で性的な意味を帯びる「下着」を選びました。この単語に対し、異なるPrefix（接頭辞）を与えることで、レイヤー29の活性化マップがどう変化するかを追跡します。

### 6.2. 実験結果

以下の3つのケースでターゲットトークンの最大活性強度を比較しました。
※ 15631（性的活動）および 9490（性的暴力）は、本実験の文脈ではいずれも 0.0 でした。

### 6.3. 洞察

この数値から、AIの脳内での挙動について非常に興味深い事実が見えてきました。

- 「性的興奮」の急峻な跳ね上がり : Prefix A（スポーツ用）や B（通販）と比較して、Prefix C（刺激的・煽情的）では Feature 2664（性的興奮）の活性化値が約3倍（560→1648）に急上昇しました。AIは「下着」という物理的実体は維持しつつも、文脈によってその内包する意味合いが「実用」から「性愛」へと明確に遷移したことを数値で示しています。
- 潜在概念の連鎖反応（Feature 14532） : 最も注目すべきは、単体や安全な文脈では全く無反応（0.0）だった Feature 14532（性的玩具）が、Prefix C の場合のみ 824.0 という有意な反応を示した点です。文脈が「煽情的」になった瞬間に、AIの脳内では直接言及されていない「アダルトグッズ」などの周辺概念までが芋づる式に呼び出されています。

### 6.4. 結論

この実験結果を、実験②で得られた「アニメ・漫画の特徴量による活性強度の変動」と組み合わせて考えると
